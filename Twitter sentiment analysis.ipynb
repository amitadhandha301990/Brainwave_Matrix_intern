{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7aad2e-07d9-4acd-afc9-cce0043ecf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebe6096a-12a2-4b73-8050-14b391651625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that s a bummer you shoulda got david car...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can t update his facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dived many times for the ball managed to sav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it s not behaving at all i m mad why am i h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523970</th>\n",
       "      <td>just woke up having no school is the best feel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523971</th>\n",
       "      <td>thewdb com very cool to hear old walt interviews</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523972</th>\n",
       "      <td>are you ready for your mojo makeover ask me fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523973</th>\n",
       "      <td>happy th birthday to my boo of alll time tupac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523974</th>\n",
       "      <td>happy charitytuesday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1523975 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sentence  sentiment\n",
       "0        awww that s a bummer you shoulda got david car...          0\n",
       "1        is upset that he can t update his facebook by ...          0\n",
       "2        i dived many times for the ball managed to sav...          0\n",
       "3           my whole body feels itchy and like its on fire          0\n",
       "4        no it s not behaving at all i m mad why am i h...          0\n",
       "...                                                    ...        ...\n",
       "1523970  just woke up having no school is the best feel...          1\n",
       "1523971  thewdb com very cool to hear old walt interviews           1\n",
       "1523972  are you ready for your mojo makeover ask me fo...          1\n",
       "1523973  happy th birthday to my boo of alll time tupac...          1\n",
       "1523974                               happy charitytuesday          1\n",
       "\n",
       "[1523975 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"E:\\\\Acods pandas\\\\Machine learning\\\\ML Projects Set-2 Data Sets\\\\Sentiment Analysis Data Set\\\\train_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aba3e97-000c-424f-aee1-b4ab8e324cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    767059\n",
       "1    756916\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "381f3fde-cddf-42b3-ba56-8e9de9843851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i loooooooovvvvvveee my kindle not that the dx...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reading my kindle love it lee childs is good read</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ok first assesment of the kindle it fucking rocks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you ll love your kindle i ve had mine for a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fair enough but i have the kindle and i think ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>after using latex a lot any other typeset math...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>on that note i hate word i hate pages i hate l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>ahhh back in a real text editing environment i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>trouble in iran i see hmm iran iran so far awa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>reading the tweets coming out of iran the whol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  sentiment\n",
       "0    i loooooooovvvvvveee my kindle not that the dx...          1\n",
       "1    reading my kindle love it lee childs is good read          1\n",
       "2    ok first assesment of the kindle it fucking rocks          1\n",
       "3    you ll love your kindle i ve had mine for a fe...          1\n",
       "4    fair enough but i have the kindle and i think ...          1\n",
       "..                                                 ...        ...\n",
       "354  after using latex a lot any other typeset math...          1\n",
       "355  on that note i hate word i hate pages i hate l...          0\n",
       "356  ahhh back in a real text editing environment i...          1\n",
       "357  trouble in iran i see hmm iran iran so far awa...          0\n",
       "358  reading the tweets coming out of iran the whol...          0\n",
       "\n",
       "[359 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"E:\\\\Acods pandas\\\\Machine learning\\\\ML Projects Set-2 Data Sets\\\\Sentiment Analysis Data Set\\\\test_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c87939d-715b-487c-bc32-672c1ae5cfbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "1    182\n",
       "0    177\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d192542-ca07-41b6-a0b4-fc316af19cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(df['sentence'].values,df['sentiment'].values, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f3cb117-e326-4f12-8365-206c3e780735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_text: pelosi should stay in china and never come back\n",
      "sentiment: 0\n"
     ]
    }
   ],
   "source": [
    "print('sentiment_text:',x_train[0])\n",
    "print('sentiment:',y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c366bc21-4cf4-4016-8a60-635d5deaaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83cdbe28-24fe-4fa6-b46d-f1ced2bdee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab=2000000\n",
    "tokenizer = Tokenizer(num_words=max_vocab)\n",
    "tokenizer.fit_on_texts(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7244bd5e-1ed6-4226-aea3-dda023540804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of dataset is: 1337\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "v=len(word_index)\n",
    "print('the size of dataset is:',v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4291a18-e508-46fd-9304-e8cc39f72b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train seq: [125, 209, 474, 14, 210, 7, 91, 148, 53]\n",
      "test seq: [1153, 54, 2, 42, 92, 7]\n"
     ]
    }
   ],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(x_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test)\n",
    "print('train seq:',train_sequences[0])\n",
    "print('test seq:',test_sequences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5513956-b4b9-41c6-8e92-2c980cc4d15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of traing set: 31\n"
     ]
    }
   ],
   "source": [
    "pad_train=pad_sequences(train_sequences)\n",
    "T=pad_train.shape[1]\n",
    "print('length of traing set:',T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5540e5d-7591-4dbf-b36a-538fe2cc2f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of traing set: 31\n"
     ]
    }
   ],
   "source": [
    "pad_test=pad_sequences(test_sequences,maxlen=T)\n",
    "T=pad_test.shape[1]\n",
    "print('length of traing set:',T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "af444d73-49f5-4207-94d9-1c420725475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8106d0d-2cbd-463e-a383-58bb238fd83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "D=20\n",
    "M=15\n",
    "\n",
    "I =Input(shape = (T, ))\n",
    "x=Embedding(v + 1, D)(I)\n",
    "x=LSTM(64, return_sequences=True)(x)\n",
    "x=GlobalMaxPooling1D()(x)\n",
    "x=Dense(32, activation='relu')(x)\n",
    "x=Dense(1, activation='sigmoid')(x)\n",
    "model=Model(I,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6cced4cd-9092-4208-a2ed-08e4274ad00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b08be87a-2a51-4d37-afe6-af85bc4af94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 187ms/step - accuracy: 0.5146 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 2/2\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5398 - loss: 0.6909 - val_accuracy: 0.5000 - val_loss: 0.6930\n"
     ]
    }
   ],
   "source": [
    "r=model.fit(pad_train,y_train,validation_data=(pad_test,y_test),epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad85ae1-be70-461b-9269-38b652eb0bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
